{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK63iN5KTxjB",
        "outputId": "9c06c4b2-111f-4e6c-e460-7a1fd8d5da24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mohamedalisalama/arabic-companies-reviews-for-sentiment-analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvrUa76NT_-L",
        "outputId": "df23cc34-2e72-4dfa-ebce-2faf37a29354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedalisalama/arabic-companies-reviews-for-sentiment-analysis\n",
            "License(s): unknown\n",
            "arabic-companies-reviews-for-sentiment-analysis.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/arabic-companies-reviews-for-sentiment-analysis.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa3U5dauUEDp",
        "outputId": "bccbe957-3b87-41e4-c532-06275a05ceb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/arabic-companies-reviews-for-sentiment-analysis.zip\n",
            "replace original_dataset.xlsx? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('/content/original_dataset.xlsx') # Use read_excel to read excel files\n",
        "print(df.head())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rch0wa8WVI8u",
        "outputId": "8cb92db2-f191-4424-e2da-c6a583102c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                 review_description  rating  \\\n",
            "0           0                         سيئ جدا بعد الإصدار الجديد      -1   \n",
            "1           1                                  ابلكيشن زباله بجد      -1   \n",
            "2           2                                 سيئ التطبيق لايعمل      -1   \n",
            "3           3  للأسف التطبيق للأسوأ كان جدا رائع وسهل وبسيط ا...      -1   \n",
            "4           4                     التحديث بطيئ جدا جدا عند الفتح      -1   \n",
            "\n",
            "       company  \n",
            "0  alahli_bank  \n",
            "1  alahli_bank  \n",
            "2  alahli_bank  \n",
            "3  alahli_bank  \n",
            "4  alahli_bank  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nDataset Features (Columns):\", df.columns.tolist())\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataset Description (Summary Statistics):\")\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC6t3npiU8oJ",
        "outputId": "1eb72954-3e46-441d-e53c-d1eae28038d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (67127, 4)\n",
            "\n",
            "Dataset Features (Columns): ['Unnamed: 0', 'review_description', 'rating', 'company']\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 67127 entries, 0 to 67126\n",
            "Data columns (total 4 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Unnamed: 0          67127 non-null  int64 \n",
            " 1   review_description  67125 non-null  object\n",
            " 2   rating              67127 non-null  int64 \n",
            " 3   company             67127 non-null  object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 2.0+ MB\n",
            "None\n",
            "\n",
            "Dataset Description (Summary Statistics):\n",
            "         Unnamed: 0        rating\n",
            "count  67127.000000  67127.000000\n",
            "mean   33563.000000     -0.040163\n",
            "std    19378.040097      0.802836\n",
            "min        0.000000     -1.000000\n",
            "25%    16781.500000     -1.000000\n",
            "50%    33563.000000      0.000000\n",
            "75%    50344.500000      1.000000\n",
            "max    67126.000000      1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nDataset Features (Columns):\", df.columns.tolist())\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataset Description (Summary Statistics):\")\n",
        "print(df.describe())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nLast 5 rows:\")\n",
        "print(df.tail())\n",
        "print(\"\\nNumber of unique values in each column:\")\n",
        "print(df.nunique())\n",
        "print(\"\\nMissing values in each column:\")\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTbWSIBPVq_H",
        "outputId": "407db3ce-a3ad-448f-e29d-bf35c91c4f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (67127, 4)\n",
            "\n",
            "Dataset Features (Columns): ['Unnamed: 0', 'review_description', 'rating', 'company']\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 67127 entries, 0 to 67126\n",
            "Data columns (total 4 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Unnamed: 0          67127 non-null  int64 \n",
            " 1   review_description  67125 non-null  object\n",
            " 2   rating              67127 non-null  int64 \n",
            " 3   company             67127 non-null  object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 2.0+ MB\n",
            "None\n",
            "\n",
            "Dataset Description (Summary Statistics):\n",
            "         Unnamed: 0        rating\n",
            "count  67127.000000  67127.000000\n",
            "mean   33563.000000     -0.040163\n",
            "std    19378.040097      0.802836\n",
            "min        0.000000     -1.000000\n",
            "25%    16781.500000     -1.000000\n",
            "50%    33563.000000      0.000000\n",
            "75%    50344.500000      1.000000\n",
            "max    67126.000000      1.000000\n",
            "\n",
            "First 5 rows:\n",
            "   Unnamed: 0                                 review_description  rating  \\\n",
            "0           0                         سيئ جدا بعد الإصدار الجديد      -1   \n",
            "1           1                                  ابلكيشن زباله بجد      -1   \n",
            "2           2                                 سيئ التطبيق لايعمل      -1   \n",
            "3           3  للأسف التطبيق للأسوأ كان جدا رائع وسهل وبسيط ا...      -1   \n",
            "4           4                     التحديث بطيئ جدا جدا عند الفتح      -1   \n",
            "\n",
            "       company  \n",
            "0  alahli_bank  \n",
            "1  alahli_bank  \n",
            "2  alahli_bank  \n",
            "3  alahli_bank  \n",
            "4  alahli_bank  \n",
            "\n",
            "Last 5 rows:\n",
            "       Unnamed: 0                                 review_description  rating  \\\n",
            "67122       67122  كتاب جيد وإن كان مملا بعض الشيء عند منتصف الكت...       0   \n",
            "67123       67123  أول تجربة مع الخيال العلمي...الكثير من المعلوم...       0   \n",
            "67124       67124  مرضي. الافطار لذيذ. لا يوجد قائمة طعام في الغر...       0   \n",
            "67125       67125  الرسائل بين وائل و شوق كانت أجمل مافي الرواية....       0   \n",
            "67126       67126  استقبال سيء جدا وعدم الاستعداد للنزلاء . لا شي...       0   \n",
            "\n",
            "      company  \n",
            "67122  hotels  \n",
            "67123  hotels  \n",
            "67124  hotels  \n",
            "67125  hotels  \n",
            "67126  hotels  \n",
            "\n",
            "Number of unique values in each column:\n",
            "Unnamed: 0            67127\n",
            "review_description    66987\n",
            "rating                    3\n",
            "company                   8\n",
            "dtype: int64\n",
            "\n",
            "Missing values in each column:\n",
            "Unnamed: 0            0\n",
            "review_description    2\n",
            "rating                0\n",
            "company               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['review_description'])\n",
        "print(\"Shape after removing missing values in 'review_description':\", df.shape)\n",
        "print(\"\\nMissing values in 'review_description' after cleaning:\", df['review_description'].isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GEFkQoWWWe-",
        "outputId": "713b58ae-4aa9-4fe6-e8f2-bb7d89d1cf39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after removing missing values in 'review_description': (67125, 4)\n",
            "\n",
            "Missing values in 'review_description' after cleaning: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nDataset Features (Columns):\", df.columns.tolist())\n",
        "print(\"\\nNumber of unique values in each column:\")\n",
        "for column in df.columns:\n",
        "  print(f\"{column}: {df[column].nunique()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQlFU9y9XMJS",
        "outputId": "c4998366-095b-40cb-8522-e9e2d7fb24ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (67125, 4)\n",
            "\n",
            "Dataset Features (Columns): ['Unnamed: 0', 'review_description', 'rating', 'company']\n",
            "\n",
            "Number of unique values in each column:\n",
            "Unnamed: 0: 67125\n",
            "review_description: 66987\n",
            "rating: 3\n",
            "company: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cdw5ObxX07x",
        "outputId": "fd72ff93-50c5-4222-cb4f-c1fe798aec34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                 review_description  rating  \\\n",
            "0           0                         سيئ جدا بعد الإصدار الجديد      -1   \n",
            "1           1                                  ابلكيشن زباله بجد      -1   \n",
            "2           2                                 سيئ التطبيق لايعمل      -1   \n",
            "3           3  للأسف التطبيق للأسوأ كان جدا رائع وسهل وبسيط ا...      -1   \n",
            "4           4                     التحديث بطيئ جدا جدا عند الفتح      -1   \n",
            "\n",
            "       company  \n",
            "0  alahli_bank  \n",
            "1  alahli_bank  \n",
            "2  alahli_bank  \n",
            "3  alahli_bank  \n",
            "4  alahli_bank  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "print(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enNJndv8X_ID",
        "outputId": "2d591b26-3982-46fd-a048-838ff7ebf7f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  review_description  rating      company\n",
            "0                         سيئ جدا بعد الإصدار الجديد      -1  alahli_bank\n",
            "1                                  ابلكيشن زباله بجد      -1  alahli_bank\n",
            "2                                 سيئ التطبيق لايعمل      -1  alahli_bank\n",
            "3  للأسف التطبيق للأسوأ كان جدا رائع وسهل وبسيط ا...      -1  alahli_bank\n",
            "4                     التحديث بطيئ جدا جدا عند الفتح      -1  alahli_bank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['rating'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCwNhs3qYIlc",
        "outputId": "49cfb9bf-0968-41e6-b794-b86e8adef70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1  0  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "\n",
        "def normalize_arabic(text):\n",
        "  text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "  text = re.sub(\"ى\", \"ي\", text)\n",
        "  text = re.sub(\"ؤ\", \"ء\", text)\n",
        "  text = re.sub(\"ئ\", \"ء\", text)\n",
        "  text = re.sub(\"ة\", \"ه\", text)\n",
        "  text = re.sub(\"گ\", \"ك\", text)\n",
        "  return text\n",
        "\n",
        "def remove_diacritics(text):\n",
        "  text = re.sub(r'[ًٌٍَُِّْ]', '', text)\n",
        "  return text\n",
        "\n",
        "def remove_special_characters(text):\n",
        "  text = re.sub('[^ء-ي ]', '', text)\n",
        "  return text\n",
        "\n",
        "def handle_elongated_words(text):\n",
        "  text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
        "  return text\n",
        "\n",
        "def tokenize_and_stem(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  stemmer = ISRIStemmer()\n",
        "  stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "  return stemmed_tokens\n",
        "\n",
        "df['review_description'] = df['review_description'].apply(lambda x: normalize_arabic(x))\n",
        "df['review_description'] = df['review_description'].apply(lambda x: remove_diacritics(x))\n",
        "df['review_description'] = df['review_description'].apply(lambda x: remove_special_characters(x))\n",
        "df['review_description'] = df['review_description'].apply(lambda x: handle_elongated_words(x))\n",
        "df['review_description'] = df['review_description'].apply(lambda x: tokenize_and_stem(x))\n",
        "\n",
        "\n",
        "print(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEyAmgslYWEA",
        "outputId": "7418ebf8-9e41-4c34-e361-53e936754886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  review_description  rating      company\n",
            "0                          [سيء, جدا, بعد, صدر, جدد]      -1  alahli_bank\n",
            "1                                    [لكش, زبل, بجد]      -1  alahli_bank\n",
            "2                                    [سيء, طبق, عمل]      -1  alahli_bank\n",
            "3  [اسف, طبق, اسا, كان, جدا, رءع, سهل, بسط, الن, ...      -1  alahli_bank\n",
            "4                     [حدث, بطء, جدا, جدا, عند, فتح]      -1  alahli_bank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['company'], axis=1)\n",
        "print(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eBknm2_ZsX-",
        "outputId": "ca40b5e0-6af7-4011-c9f8-07cc11ad4949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  review_description  rating\n",
            "0                          [سيء, جدا, بعد, صدر, جدد]      -1\n",
            "1                                    [لكش, زبل, بجد]      -1\n",
            "2                                    [سيء, طبق, عمل]      -1\n",
            "3  [اسف, طبق, اسا, كان, جدا, رءع, سهل, بسط, الن, ...      -1\n",
            "4                     [حدث, بطء, جدا, جدا, عند, فتح]      -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarabic\n",
        "from pyarabic.araby import normalize_hamza, strip_tashkeel\n",
        "\n",
        "def correct_arabic_spelling(text):\n",
        "  if isinstance(text, list):\n",
        "    corrected_text = [normalize_hamza(strip_tashkeel(word)) for word in text]\n",
        "    return corrected_text\n",
        "  else:\n",
        "    return text\n",
        "\n",
        "df['review_description'] = df['review_description'].apply(lambda x: correct_arabic_spelling(x))\n",
        "print(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SyQojeDZwwV",
        "outputId": "975b05c4-cfa3-41bf-f5dc-adf170fa0854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.10/dist-packages (0.6.15)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic) (1.16.0)\n",
            "                                  review_description  rating\n",
            "0                          [سيء, جدا, بعد, صدر, جدد]      -1\n",
            "1                                    [لكش, زبل, بجد]      -1\n",
            "2                                    [سيء, طبق, عمل]      -1\n",
            "3  [اسف, طبق, اسا, كان, جدا, رءع, سهل, بسط, الن, ...      -1\n",
            "4                     [حدث, بطء, جدا, جدا, عند, فتح]      -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def find_emojis(text):\n",
        "  if isinstance(text, list):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    emojis = emoji_pattern.findall(\" \".join(text))\n",
        "    return emojis\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "\n",
        "df['emojis'] = df['review_description'].apply(lambda x: find_emojis(x))\n",
        "rows_with_emojis = df[df['emojis'].apply(lambda x: len(x) > 0)]\n",
        "print(f\"Number of rows with emojis: {len(rows_with_emojis)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_spxsmSdqWS",
        "outputId": "6cfce3d1-2acc-4882-d3f6-39242388bfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with emojis: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Check the class distribution of the 'rating' column\n",
        "rating_counts = df['rating'].value_counts()\n",
        "print(\"Class Distribution Before Oversampling:\\n\", rating_counts)\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('rating', axis=1)\n",
        "y = df['rating']\n",
        "\n",
        "# Apply Random Oversampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "\n",
        "# Convert the resampled data back to a DataFrame\n",
        "df_resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "# Check the class distribution after oversampling\n",
        "rating_counts_resampled = df_resampled['rating'].value_counts()\n",
        "print(\"\\nClass Distribution After Oversampling:\\n\", rating_counts_resampled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsUtmQssffHE",
        "outputId": "14b2a5e9-4869-4477-cea4-365baf2804a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution Before Oversampling:\n",
            " rating\n",
            " 0    23751\n",
            "-1    23035\n",
            " 1    20339\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class Distribution After Oversampling:\n",
            " rating\n",
            "-1    23751\n",
            " 0    23751\n",
            " 1    23751\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'df_resampled' contains your balanced dataset with 'review_description' and 'rating' columns\n",
        "\n",
        "# 1. Prepare the data\n",
        "reviews = df_resampled['review_description'].tolist()\n",
        "ratings = df_resampled['rating'].tolist()\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # Adjust num_words as needed\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "\n",
        "# Pad sequences to have the same length\n",
        "max_length = 100  # Adjust max_length as needed\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# 2. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure the input data is in the correct format (NumPy arrays)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# 3. Convert labels to categorical format\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train + 1, num_classes=3)\n",
        "y_test = to_categorical(y_test + 1, num_classes=3)\n",
        "\"\"\"\n",
        "# Convert to categorical (one-hot encoding)\n",
        "y_train = to_categorical(y_train + 1, num_classes=3)  # Shift labels: -1 -> 0, 0 -> 1, 1 -> 2\n",
        "y_test = to_categorical(y_test + 1, num_classes=3)\n",
        "\"\"\"\n",
        "# 4. Build the LSTM model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 128  # Adjust embedding_dim as needed\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))  # Add dropout for regularization\n",
        "model.add(Dense(3, activation='softmax'))  # Use softmax for multi-class classification\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Use categorical_crossentropy\n",
        "\n",
        "# 6. Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))  # Adjust epochs and batch_size as needed\n",
        "\n",
        "# 7. Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id2yrSpmuTHn",
        "outputId": "b8f37448-ef90-4e06-e5a8-7ed564ed4ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 243ms/step - accuracy: 0.5010 - loss: 0.9351 - val_accuracy: 0.5261 - val_loss: 1.2068\n",
            "Epoch 2/10\n",
            "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 251ms/step - accuracy: 0.8234 - loss: 0.4942 - val_accuracy: 0.8782 - val_loss: 0.3521\n",
            "Epoch 3/10\n",
            "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 243ms/step - accuracy: 0.8863 - loss: 0.3209 - val_accuracy: 0.8796 - val_loss: 0.3374\n",
            "Epoch 4/10\n",
            "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 241ms/step - accuracy: 0.8984 - loss: 0.2854 - val_accuracy: 0.8794 - val_loss: 0.3349\n",
            "Epoch 5/10\n",
            "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 254ms/step - accuracy: 0.9066 - loss: 0.2603 - val_accuracy: 0.8809 - val_loss: 0.3385\n",
            "Epoch 6/10\n",
            "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 243ms/step - accuracy: 0.9121 - loss: 0.2445 - val_accuracy: 0.8801 - val_loss: 0.3561\n",
            "Epoch 7/10\n",
            "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 251ms/step - accuracy: 0.9213 - loss: 0.2160 - val_accuracy: 0.8801 - val_loss: 0.3600\n",
            "Epoch 8/10\n",
            "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 244ms/step - accuracy: 0.9262 - loss: 0.2064 - val_accuracy: 0.8778 - val_loss: 0.3806\n",
            "Epoch 9/10\n",
            "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 247ms/step - accuracy: 0.9300 - loss: 0.1900 - val_accuracy: 0.8766 - val_loss: 0.3971\n",
            "Epoch 10/10\n",
            "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 248ms/step - accuracy: 0.9357 - loss: 0.1797 - val_accuracy: 0.8755 - val_loss: 0.4215\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 63ms/step - accuracy: 0.8758 - loss: 0.4255\n",
            "Test Loss: 0.4214668273925781\n",
            "Test Accuracy: 0.8755174875259399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get predicted probabilities for the test set\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Convert one-hot encoded true labels to class labels\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Generate the classification report\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvvXgCzTyieb",
        "outputId": "61798257-7222-4be0-a699-2f14a7f98ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88      4788\n",
            "           1       0.92      0.84      0.88      4785\n",
            "           2       0.84      0.89      0.87      4678\n",
            "\n",
            "    accuracy                           0.88     14251\n",
            "   macro avg       0.88      0.88      0.88     14251\n",
            "weighted avg       0.88      0.88      0.88     14251\n",
            "\n"
          ]
        }
      ]
    }
  ]
}